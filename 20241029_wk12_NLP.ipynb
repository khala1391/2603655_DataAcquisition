{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2603655_DataAcquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week12 20241029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "* Author:  [Yuttapong Mahasittiwat](mailto:khala1391@gmail.com)\n",
    "* Technologist | Data Modeler | Data Analyst\n",
    "* [YouTube](https://www.youtube.com/khala1391)\n",
    "* [LinkedIn](https://www.linkedin.com/in/yuttapong-m/)\n",
    "* [Tableau](https://public.tableau.com/app/profile/yuttapong.m/vizzes)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref:\n",
    "- [perplexity:NLP](https://www.perplexity.ai/page/nlp-radabphuuenthaan-3nOx9HZVS_ae5ZRwlr9vVw)\n",
    "- [perplexity:RegEx](https://www.perplexity.ai/page/regular-expressions-in-python-jTm0K1iFRSi24HmW3NJfTA)\n",
    "- [perplexity:HuggingFace](https://www.perplexity.ai/page/hugging-face-token-guide-Ze2MvWjYRIiSkNaFBDWAlw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-21 15:58:32.397457\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegEx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".       - Any Character Except New Line\n",
    "\\d      - Digit (0-9)\n",
    "\\D      - Not a Digit (0-9)\n",
    "\\w      - Word Character (a-z, A-Z, 0-9, _)\n",
    "\\W      - Not a Word Character\n",
    "\\s      - Whitespace (space, tab, newline)\n",
    "\\S      - Not Whitespace (space, tab, newline)\n",
    "\n",
    "\\b      - Word Boundary\n",
    "\\B      - Not a Word Boundary\n",
    "^       - Beginning of a String\n",
    "$       - End of a String\n",
    "\n",
    "[]      - Matches Characters in brackets\n",
    "[^ ]    - Matches Characters NOT in brackets\n",
    "|       - Either Or\n",
    "( )     - Group\n",
    "\n",
    "Quantifiers:\n",
    "*       - 0 or More\n",
    "+       - 1 or More\n",
    "?       - 0 or One\n",
    "{3}     - Exact Number\n",
    "{3,4}   - Range of Numbers (Minimum, Maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegEX in string data\n",
    " - `re.search`\n",
    " - `re.match`\n",
    " - `re.findall`\n",
    " - `re.finditer` (+ for loop i.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLAG\n",
    "- `re.IGNORECASE`\n",
    "- `re.MULTILINE` or `re.M` : combination with `^` for match all line\n",
    "- `re.DOTALL` or `re.S`  : search through new line\n",
    "- `re.VERBOSE` or `re.X`\n",
    "- `re.ASCII` or `re.A`\n",
    "- `re.DEBUG`\n",
    "- `re.LOCALE` or `re.L`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result from re.search <re.Match object; span=(18, 22), match='John'>\n",
      "result from re.match None\n",
      "result when not use flag: None\n",
      "result when use flag: re.IGNORECASE <re.Match object; span=(0, 5), match='HELLO'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"สวัสดีครับ ผมชื่อ John\"\n",
    "\n",
    "result = re.search(r'John', text)\n",
    "print(f'result from re.search {result}')\n",
    "\n",
    "result = re.match(r'John', text)\n",
    "print(f'result from re.match {result}')\n",
    "\n",
    "text = \"HELLO world\"\n",
    "result = re.search(r'hello', text)\n",
    "print(f'result when not use flag: {result}')\n",
    "\n",
    "text = \"HELLO world\"\n",
    "result = re.search(r'hello', text, re.IGNORECASE)\n",
    "print(f'result when use flag: re.IGNORECASE {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found:\n",
      "Hello there, World\n",
      "Hello everyone, World\n",
      "Hello again, World\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample multi-line text\n",
    "text = \"\"\"Hello there, World\n",
    "Goodbye there, World\n",
    "Hello everyone, World\n",
    "Just a simple line\n",
    "Hello again, World\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression pattern with re.M\n",
    "pattern = r'^Hello.*World$'\n",
    "\n",
    "# Using re.MULTILINE to match start and end of each line\n",
    "matches = re.findall(pattern, text, re.MULTILINE)\n",
    "\n",
    "# Print the matches found\n",
    "print(\"Matches found:\")\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found without DOTALL: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample multi-line text\n",
    "text = \"\"\"This is a sample text.\n",
    "<start>\n",
    "This text is\n",
    "spanning multiple lines.\n",
    "<end>\n",
    "This is outside the tags.\"\"\"\n",
    "\n",
    "# Regular expression to find text between <start> and <end> tags\n",
    "pattern = r'<start>(.*?)<end>'\n",
    "\n",
    "# Using the regex without re.DOTALL\n",
    "matches_no_dotall = re.findall(pattern, text)\n",
    "\n",
    "print(\"Matches found without DOTALL:\", matches_no_dotall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found:\n",
      "(123) 456-7890\n",
      "(987) 654-3210\n",
      "(555) 123-4567\n",
      "(444) 222-3333\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample text containing phone numbers\n",
    "text = \"\"\"\n",
    "Here are some phone numbers:\n",
    "(123) 456-7890\n",
    "(987) 654-3210\n",
    "Call me at (555) 123-4567 or (444) 222-3333!\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression with re.X for clarity\n",
    "pattern = r\"\"\"\n",
    "    \\(\\d{3}\\)      # Area code in parentheses\n",
    "    \\s             # Space after area code\n",
    "    \\d{3}          # First three digits\n",
    "    -              # Hyphen\n",
    "    \\d{4}          # Last four digits\n",
    "\"\"\"\n",
    "\n",
    "# Using re.X to enable verbose mode\n",
    "matches = re.findall(pattern, text, re.VERBOSE)\n",
    "\n",
    "# Print the matches found\n",
    "print(\"Matches found:\")\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result from re.findall: ['ส้ม', 'ส้ม']\n",
      "result from re.findall: []\n"
     ]
    }
   ],
   "source": [
    "text = \"ฉันชอบกินส้ม กล้วย และส้ม\"\n",
    "result = re.findall(r'ส้ม', text)\n",
    "print(f'result from re.findall: {result}')   # list\n",
    "\n",
    "result = re.findall(r'มะละกอ', text)\n",
    "print(f'result from re.findall: {result}')   # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02-123-4567', '081-234-5678']\n"
     ]
    }
   ],
   "source": [
    "text = \"เบอร์โทรของฉันคือ 02-123-4567 และ 081-234-5678\"\n",
    "result = re.findall(r'\\d{2,3}-\\d{3}-\\d{4}', text)\n",
    "print(result)  # ['02-123-4567', '081-234-5678']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-123-4567\n",
      "081-234-5678\n"
     ]
    }
   ],
   "source": [
    "text = \"เบอร์โทรของฉันคือ 02-123-4567 และ 081-234-5678\"\n",
    "result = re.finditer(r'\\d{2,3}-\\d{3}-\\d{4}', text)\n",
    "\n",
    "for i in result:\n",
    "    print(i.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-123-4567', '081-234-5678']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"เบอร์โทรของฉันคือ 02-123-4567 และ 081-234-5678\"\n",
    "result = re.finditer(r'\\d{2,3}-\\d{3}-\\d{4}', text)\n",
    "\n",
    "matches = [i.group() for i in result]\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(18, 29), match='02-123-4567'>,\n",
       " <re.Match object; span=(34, 46), match='081-234-5678'>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"เบอร์โทรของฉันคือ 02-123-4567 และ 081-234-5678\"\n",
    "result = re.finditer(r'\\d{2,3}-\\d{3}-\\d{4}', text)\n",
    "\n",
    "matches = [i for i in result]\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegEx in Df\n",
    "- `str.startswith`\n",
    "- `str.endswith`\n",
    "- `str.contains`\n",
    "- `str.replace`\n",
    "  - Series.str.replace(pat, repl, n=-1, case=None, regex=True) => n: no.for replacement\n",
    "- `str.extract`\n",
    "- `str.findall`\n",
    "- `str.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       full name    id   education    university    tel number zipcode\n",
      "0  Alice Johnson  A001  Bachelor's  University A   02-123-4567  AB1001\n",
      "1      Bob Smith  B002    Master's  University B  081-234-5678  CD2002\n",
      "2  Charlie Brown  C003         PhD  University C   03-456-7890  EF3003\n",
      "3   Diana Prince  D004  Bachelor's  University D  082-345-6789  GH4004\n",
      "4    Evan Thomas  E005   Associate  University E   04-567-8901  IJ5005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for the DataFrame\n",
    "data = {\n",
    "    \"full name\": [\"Alice Johnson\", \"Bob Smith\", \"Charlie Brown\", \"Diana Prince\", \"Evan Thomas\"],\n",
    "    \"id\": [\"A001\", \"B002\", \"C003\", \"D004\", \"E005\"],\n",
    "    \"education\": [\"Bachelor's\", \"Master's\", \"PhD\", \"Bachelor's\", \"Associate\"],\n",
    "    \"university\": [\"University A\", \"University B\", \"University C\", \"University D\", \"University E\"],\n",
    "    \"tel number\": [\"02-123-4567\", \"081-234-5678\", \"03-456-7890\", \"082-345-6789\", \"04-567-8901\"],\n",
    "    \"zipcode\": [\"AB1001\", \"CD2002\", \"EF3003\", \"GH4004\", \"IJ5005\"]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>University B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education    university    tel number zipcode\n",
       "0  Alice Johnson  A001  Bachelor's  University A   02-123-4567  AB1001\n",
       "1      Bob Smith  B002    Master's  University B  081-234-5678  CD2002\n",
       "3   Diana Prince  D004  Bachelor's  University D  082-345-6789  GH4004"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series.str.contains(pat, case=True, flags=0, na=None, regex=True)\n",
    "\n",
    "df[df['education'].str.contains(r'\\'s')] # regex = True (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>University B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education    university    tel number zipcode\n",
       "0  Alice Johnson  A001  Bachelor's  University A   02-123-4567  AB1001\n",
       "1      Bob Smith  B002    Master's  University B  081-234-5678  CD2002\n",
       "3   Diana Prince  D004  Bachelor's  University D  082-345-6789  GH4004"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['education'].str.contains('[MB]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>School B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>C003</td>\n",
       "      <td>PhD</td>\n",
       "      <td>School C</td>\n",
       "      <td>03-456-7890</td>\n",
       "      <td>EF3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>E005</td>\n",
       "      <td>Associate</td>\n",
       "      <td>School E</td>\n",
       "      <td>04-567-8901</td>\n",
       "      <td>IJ5005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education university    tel number zipcode\n",
       "0  Alice Johnson  A001  Bachelor's   School A   02-123-4567  AB1001\n",
       "1      Bob Smith  B002    Master's   School B  081-234-5678  CD2002\n",
       "2  Charlie Brown  C003         PhD   School C   03-456-7890  EF3003\n",
       "3   Diana Prince  D004  Bachelor's   School D  082-345-6789  GH4004\n",
       "4    Evan Thomas  E005   Associate   School E   04-567-8901  IJ5005"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['university'] = df['university'].str.replace('University', 'School')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipcode_character</th>\n",
       "      <th>zipcode_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "      <td>AB</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>School B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "      <td>CD</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>C003</td>\n",
       "      <td>PhD</td>\n",
       "      <td>School C</td>\n",
       "      <td>03-456-7890</td>\n",
       "      <td>EF3003</td>\n",
       "      <td>EF</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "      <td>GH</td>\n",
       "      <td>4004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>E005</td>\n",
       "      <td>Associate</td>\n",
       "      <td>School E</td>\n",
       "      <td>04-567-8901</td>\n",
       "      <td>IJ5005</td>\n",
       "      <td>IJ</td>\n",
       "      <td>5005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education university    tel number zipcode  \\\n",
       "0  Alice Johnson  A001  Bachelor's   School A   02-123-4567  AB1001   \n",
       "1      Bob Smith  B002    Master's   School B  081-234-5678  CD2002   \n",
       "2  Charlie Brown  C003         PhD   School C   03-456-7890  EF3003   \n",
       "3   Diana Prince  D004  Bachelor's   School D  082-345-6789  GH4004   \n",
       "4    Evan Thomas  E005   Associate   School E   04-567-8901  IJ5005   \n",
       "\n",
       "  zipcode_character zipcode_number  \n",
       "0                AB           1001  \n",
       "1                CD           2002  \n",
       "2                EF           3003  \n",
       "3                GH           4004  \n",
       "4                IJ           5005  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['zipcode_character']= df['zipcode'].str.extract('(\\w[a-zA-Z]+)')\n",
    "df['zipcode_number']= df['zipcode'].str.extract('(\\d+)')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipcode_character</th>\n",
       "      <th>zipcode_number</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "      <td>AB</td>\n",
       "      <td>1001</td>\n",
       "      <td>[-, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>School B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "      <td>CD</td>\n",
       "      <td>2002</td>\n",
       "      <td>[-, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>C003</td>\n",
       "      <td>PhD</td>\n",
       "      <td>School C</td>\n",
       "      <td>03-456-7890</td>\n",
       "      <td>EF3003</td>\n",
       "      <td>EF</td>\n",
       "      <td>3003</td>\n",
       "      <td>[-, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "      <td>GH</td>\n",
       "      <td>4004</td>\n",
       "      <td>[-, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>E005</td>\n",
       "      <td>Associate</td>\n",
       "      <td>School E</td>\n",
       "      <td>04-567-8901</td>\n",
       "      <td>IJ5005</td>\n",
       "      <td>IJ</td>\n",
       "      <td>5005</td>\n",
       "      <td>[-, -]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education university    tel number zipcode  \\\n",
       "0  Alice Johnson  A001  Bachelor's   School A   02-123-4567  AB1001   \n",
       "1      Bob Smith  B002    Master's   School B  081-234-5678  CD2002   \n",
       "2  Charlie Brown  C003         PhD   School C   03-456-7890  EF3003   \n",
       "3   Diana Prince  D004  Bachelor's   School D  082-345-6789  GH4004   \n",
       "4    Evan Thomas  E005   Associate   School E   04-567-8901  IJ5005   \n",
       "\n",
       "  zipcode_character zipcode_number   match  \n",
       "0                AB           1001  [-, -]  \n",
       "1                CD           2002  [-, -]  \n",
       "2                EF           3003  [-, -]  \n",
       "3                GH           4004  [-, -]  \n",
       "4                IJ           5005  [-, -]  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['match']= df['tel number'].str.findall('[-]')  # list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipcode_character</th>\n",
       "      <th>zipcode_number</th>\n",
       "      <th>match</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "      <td>AB</td>\n",
       "      <td>1001</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>School B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "      <td>CD</td>\n",
       "      <td>2002</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>C003</td>\n",
       "      <td>PhD</td>\n",
       "      <td>School C</td>\n",
       "      <td>03-456-7890</td>\n",
       "      <td>EF3003</td>\n",
       "      <td>EF</td>\n",
       "      <td>3003</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "      <td>GH</td>\n",
       "      <td>4004</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Diana</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>E005</td>\n",
       "      <td>Associate</td>\n",
       "      <td>School E</td>\n",
       "      <td>04-567-8901</td>\n",
       "      <td>IJ5005</td>\n",
       "      <td>IJ</td>\n",
       "      <td>5005</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Evan</td>\n",
       "      <td>Thomas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education university    tel number zipcode  \\\n",
       "0  Alice Johnson  A001  Bachelor's   School A   02-123-4567  AB1001   \n",
       "1      Bob Smith  B002    Master's   School B  081-234-5678  CD2002   \n",
       "2  Charlie Brown  C003         PhD   School C   03-456-7890  EF3003   \n",
       "3   Diana Prince  D004  Bachelor's   School D  082-345-6789  GH4004   \n",
       "4    Evan Thomas  E005   Associate   School E   04-567-8901  IJ5005   \n",
       "\n",
       "  zipcode_character zipcode_number   match first_name last_name  \n",
       "0                AB           1001  [-, -]      Alice   Johnson  \n",
       "1                CD           2002  [-, -]        Bob     Smith  \n",
       "2                EF           3003  [-, -]    Charlie     Brown  \n",
       "3                GH           4004  [-, -]      Diana    Prince  \n",
       "4                IJ           5005  [-, -]       Evan    Thomas  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['first_name', 'last_name']] = df['full name'].str.split(r'\\s+', expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>id</th>\n",
       "      <th>education</th>\n",
       "      <th>university</th>\n",
       "      <th>tel number</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipcode_character</th>\n",
       "      <th>zipcode_number</th>\n",
       "      <th>match</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>A001</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School A</td>\n",
       "      <td>02-123-4567</td>\n",
       "      <td>AB1001</td>\n",
       "      <td>AB</td>\n",
       "      <td>1001</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>[Alice, Johnson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>B002</td>\n",
       "      <td>Master's</td>\n",
       "      <td>School B</td>\n",
       "      <td>081-234-5678</td>\n",
       "      <td>CD2002</td>\n",
       "      <td>CD</td>\n",
       "      <td>2002</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Smith</td>\n",
       "      <td>[Bob, Smith]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>C003</td>\n",
       "      <td>PhD</td>\n",
       "      <td>School C</td>\n",
       "      <td>03-456-7890</td>\n",
       "      <td>EF3003</td>\n",
       "      <td>EF</td>\n",
       "      <td>3003</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>Brown</td>\n",
       "      <td>[Charlie, Brown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>D004</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>School D</td>\n",
       "      <td>082-345-6789</td>\n",
       "      <td>GH4004</td>\n",
       "      <td>GH</td>\n",
       "      <td>4004</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Diana</td>\n",
       "      <td>Prince</td>\n",
       "      <td>[Diana, Prince]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>E005</td>\n",
       "      <td>Associate</td>\n",
       "      <td>School E</td>\n",
       "      <td>04-567-8901</td>\n",
       "      <td>IJ5005</td>\n",
       "      <td>IJ</td>\n",
       "      <td>5005</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>Evan</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>[Evan, Thomas]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full name    id   education university    tel number zipcode  \\\n",
       "0  Alice Johnson  A001  Bachelor's   School A   02-123-4567  AB1001   \n",
       "1      Bob Smith  B002    Master's   School B  081-234-5678  CD2002   \n",
       "2  Charlie Brown  C003         PhD   School C   03-456-7890  EF3003   \n",
       "3   Diana Prince  D004  Bachelor's   School D  082-345-6789  GH4004   \n",
       "4    Evan Thomas  E005   Associate   School E   04-567-8901  IJ5005   \n",
       "\n",
       "  zipcode_character zipcode_number   match first_name last_name  \\\n",
       "0                AB           1001  [-, -]      Alice   Johnson   \n",
       "1                CD           2002  [-, -]        Bob     Smith   \n",
       "2                EF           3003  [-, -]    Charlie     Brown   \n",
       "3                GH           4004  [-, -]      Diana    Prince   \n",
       "4                IJ           5005  [-, -]       Evan    Thomas   \n",
       "\n",
       "                new  \n",
       "0  [Alice, Johnson]  \n",
       "1      [Bob, Smith]  \n",
       "2  [Charlie, Brown]  \n",
       "3   [Diana, Prince]  \n",
       "4    [Evan, Thomas]  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new'] = df['full name'].str.split(r'\\s+')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert data to JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blognone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    50 non-null     object\n",
      " 1   content  50 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 932.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>รีวิว ASUS ROG Ally X เทียบ ROG Ally รุ่นแรก ค...</td>\n",
       "      <td>ในช่วง 2-3 ปีที่ผ่านมา วงการเกมมีความเคลื่อนไห...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meta นำ Facial Recognition มาใช้งานอีกครั้งหลั...</td>\n",
       "      <td>Meta เตรียมนำระบบรู้จำใบหน้าหรือ Facial Recogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google เตรียมปิดการทำงานกล่อง Search ย่อยเจาะจ...</td>\n",
       "      <td>กูเกิลแจ้งการปิดการทำงานกล่องค้นหาย่อยในผลค้นห...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>อีกบทบาทของ Tim Cook - ที่ปรึกษาบริษัท Nike ซึ...</td>\n",
       "      <td>Tim Cook ซีอีโอแอปเปิล เป็นที่รู้จักในฐานะซีอี...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nvidia จะเข้ามาลงทุนในประเทศไทย Jensen Huang เ...</td>\n",
       "      <td>นายพิชัย นริพทะพันธุ์ รัฐมนตรีว่าการกระทรวงพาณ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  รีวิว ASUS ROG Ally X เทียบ ROG Ally รุ่นแรก ค...   \n",
       "1  Meta นำ Facial Recognition มาใช้งานอีกครั้งหลั...   \n",
       "2  Google เตรียมปิดการทำงานกล่อง Search ย่อยเจาะจ...   \n",
       "3  อีกบทบาทของ Tim Cook - ที่ปรึกษาบริษัท Nike ซึ...   \n",
       "4  Nvidia จะเข้ามาลงทุนในประเทศไทย Jensen Huang เ...   \n",
       "\n",
       "                                             content  \n",
       "0  ในช่วง 2-3 ปีที่ผ่านมา วงการเกมมีความเคลื่อนไห...  \n",
       "1  Meta เตรียมนำระบบรู้จำใบหน้าหรือ Facial Recogn...  \n",
       "2  กูเกิลแจ้งการปิดการทำงานกล่องค้นหาย่อยในผลค้นห...  \n",
       "3  Tim Cook ซีอีโอแอปเปิล เป็นที่รู้จักในฐานะซีอี...  \n",
       "4  นายพิชัย นริพทะพันธุ์ รัฐมนตรีว่าการกระทรวงพาณ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import textwrap\n",
    "\n",
    "zipf =zipfile.ZipFile('data/blognone.zip','r')\n",
    "filenames = zipf.namelist()\n",
    "\n",
    "corpus_content = list()\n",
    "\n",
    "# for filename in filenames[:1]:\n",
    "for filename in filenames:\n",
    "    html_file =zipf.open(filename)\n",
    "    html_string = html_file.read().decode('utf-8')\n",
    "    html_file.close()\n",
    "\n",
    "    html_soup = BeautifulSoup(html_string, 'html.parser')\n",
    "    # print(html_soup.prettify())\n",
    "    \n",
    "    title_box = html_soup.find('div', class_='content-title-box')\n",
    "    title = title_box.find('a').get('title')\n",
    "    # print(title)\n",
    "    \n",
    "    content_box = html_soup.find('div', class_='field field-name-body field-type-text-with-summary field-label-hidden')\n",
    "    # print(context_box.text)\n",
    "    content = content_box.text\n",
    "    content = content.replace('\\n','').replace('  ','')\n",
    "    # print(textwrap.fill(content,width=120))\n",
    "    \n",
    "    corpus_content.append({'title': title,\n",
    "                           'content': content,\n",
    "                           })\n",
    "zipf.close()\n",
    "\n",
    "df_corpus = pd.DataFrame(corpus_content)\n",
    "df_corpus.info()\n",
    "df_corpus.head()\n",
    "display(df_corpus.head())\n",
    "df_corpus.to_json('data/blognone.json', orient='table', force_ascii=False, indent=2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Khaosod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    52 non-null     object\n",
      " 1   content  52 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 964.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>หลาก&amp;หลายไอที - อลังการไลน์อัพโน้ตบุ๊กAI  เลอโ...</td>\n",
       "      <td>เลอโนโวเปิดตัวผลิตภัณฑ์ใหม่ล่าสุดของไลน์อัพ Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>หลาก&amp;หลายไอที - อลังการแอปเปิ้ลอีเวนต์  ชูไอโฟ...</td>\n",
       "      <td>นอกจากสินค้าเรือธงอย่าง iPhone 16 series ซึ่งแ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>สาวกห้ามพลาด เทียบราคา iPhone16 ถูกกว่า iPhone15</td>\n",
       "      <td>สาวก Apple ห้ามพลาด เทียบราคา iPhone16 ถูกกว่า...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>หลาก&amp;หลายไอที - ‘แผ่นพิมพ์วงจรไฟฟ้า’โอกาสไทย-ผ...</td>\n",
       "      <td>ประเทศไทยกำลังอยู่ในช่วงหัวเลี้ยวหัวต่อสำคัญขอ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>หลาก&amp;หลายไอที - ‘แผ่นพิมพ์วงจรไฟฟ้า’  โอกาสไทย...</td>\n",
       "      <td>แผ่นพิมพ์วงจรไฟฟ้าหรือ พีซีบีเป็นรากฐานที่สำคั...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  หลาก&หลายไอที - อลังการไลน์อัพโน้ตบุ๊กAI  เลอโ...   \n",
       "1  หลาก&หลายไอที - อลังการแอปเปิ้ลอีเวนต์  ชูไอโฟ...   \n",
       "2   สาวกห้ามพลาด เทียบราคา iPhone16 ถูกกว่า iPhone15   \n",
       "3  หลาก&หลายไอที - ‘แผ่นพิมพ์วงจรไฟฟ้า’โอกาสไทย-ผ...   \n",
       "4  หลาก&หลายไอที - ‘แผ่นพิมพ์วงจรไฟฟ้า’  โอกาสไทย...   \n",
       "\n",
       "                                             content  \n",
       "0  เลอโนโวเปิดตัวผลิตภัณฑ์ใหม่ล่าสุดของไลน์อัพ Le...  \n",
       "1  นอกจากสินค้าเรือธงอย่าง iPhone 16 series ซึ่งแ...  \n",
       "2  สาวก Apple ห้ามพลาด เทียบราคา iPhone16 ถูกกว่า...  \n",
       "3  ประเทศไทยกำลังอยู่ในช่วงหัวเลี้ยวหัวต่อสำคัญขอ...  \n",
       "4  แผ่นพิมพ์วงจรไฟฟ้าหรือ พีซีบีเป็นรากฐานที่สำคั...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "zipf = zipfile.ZipFile('data/khaosod.zip','r')\n",
    "filenames = zipf.namelist()\n",
    "\n",
    "corpus_content = list()\n",
    "\n",
    "# for filename in filenames[:1]:\n",
    "for filename in filenames:\n",
    "  html_file = zipf.open(filename)\n",
    "  html_string = html_file.read().decode('utf-8')\n",
    "  html_file.close()\n",
    "\n",
    "  html_soup = BeautifulSoup(html_string,'html.parser')\n",
    "  # print(html_soup.prettify())\n",
    "\n",
    "  title_box = html_soup.find('h1',class_='udsg__main-title')\n",
    "  title = title_box.text.strip()\n",
    "  # print(title)\n",
    "\n",
    "  content_box = html_soup.find('div',class_='udsg__content')\n",
    "  content = ''\n",
    "  for p in content_box.find_all('p'):\n",
    "    content += p.text\n",
    "  content = content.replace('\\n','').replace('  ','').strip()\n",
    "  # print(textwrap.fill(content,width=120))\n",
    "\n",
    "  corpus_content.append({'title':title,\n",
    "                         'content':content\n",
    "                        })\n",
    "zipf.close()\n",
    "\n",
    "df_corpus = pd.DataFrame(corpus_content)\n",
    "df_corpus.info()\n",
    "display(df_corpus.head())\n",
    "df_corpus.to_json('data/khaosod.json',orient='table',force_ascii=False,indent=2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read json to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pythainlp\n",
      "  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\khala\\anaconda3\\lib\\site-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\khala\\anaconda3\\lib\\site-packages (from pythainlp) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khala\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khala\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khala\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khala\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2024.7.4)\n",
      "Downloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n",
      "   ---------------------------------------- 0.0/17.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/17.9 MB 3.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.3/17.9 MB 3.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.4/17.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.1/17.9 MB 3.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.9/17.9 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.7/17.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 5.8/17.9 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 6.8/17.9 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.6/17.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 8.7/17.9 MB 4.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 9.7/17.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 10.5/17.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 11.3/17.9 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.3/17.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 13.4/17.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 14.2/17.9 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.2/17.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.0/17.9 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.0/17.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.9/17.9 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pythainlp\n",
      "Successfully installed pythainlp-5.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\khala\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\khala\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\khala\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_blognone = pd.read_json('data/blognone.json',orient='table')\n",
    "df_khaosod = pd.read_json('data/khaosod.json',orient='table')\n",
    "df = pd.concat([df_blognone,df_khaosod])\n",
    "content = ''.join(df['content'].tolist())\n",
    "\n",
    "# print(len(content))\n",
    "# print(content[:200])\n",
    "f = open('data/content.txt','w',encoding='utf-8')\n",
    "f.write(content)\n",
    "f.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenize 1-gram by dict-newmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ใน', 'ช่วง', 'ปี', 'ที่ผ่านมา', 'วงการ', 'เกม', 'มี', 'ความเคลื่อนไหว', 'มากขึ้น', 'จาก', 'กระแส', 'ที่', 'กลับมา', 'ของ', 'Handheld', 'Console', 'หรือ', 'เครื่องเล่นเกม', 'พกพา', 'ที่', 'ได้ประโยชน์', 'จาก', 'พัฒนาการ', 'ด้าน', 'ฮาร์ดแวร์', 'ที่', 'แรง', 'มากขึ้น', 'ระดับ', 'หนึ่ง', 'จน', 'สามารถ', 'นำ', 'สโตร์', 'เกม', 'อันดับ', 'อย่าง', 'Steam', 'มา', 'อยู่', 'ใน', 'ขนาดที่', 'พกพา', 'ได้', 'ROG', 'เป็นหนึ่ง', 'ใน', 'แบรนด์', 'ที่', 'ดู']\n",
      "55218\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize,Tokenizer\n",
    "\n",
    "f = open('data/content.txt','r',encoding='utf-8')\n",
    "content = f.read()\n",
    "f.close()\n",
    "\n",
    "tokens = [token for token in word_tokenize(content,engine='newmm')\n",
    "                             if len(token) > 1]\n",
    "print(tokens[:50])\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenize 2-gram by dict-newmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('สมาร์ต', 'โฟน'), 92)\n",
      "(('ที่', 'มี'), 90)\n",
      "(('ความ', 'ละเอียด'), 86)\n",
      "(('มา', 'พร้อม'), 77)\n",
      "(('เอ', 'ไอ'), 68)\n",
      "(('ใน', 'การ'), 65)\n",
      "(('เล่น', 'เกม'), 57)\n",
      "(('เอ', 'ซุส'), 57)\n",
      "(('ไม่', 'ได้'), 52)\n",
      "(('จาก', 'ค่าย'), 52)\n",
      "(('ว่า', 'จะ'), 50)\n",
      "(('ช่วย', 'ให้'), 47)\n",
      "(('ได้', 'อย่าง'), 47)\n",
      "(('พีซี', 'บี'), 47)\n",
      "(('ตัว', 'เครื่อง'), 45)\n",
      "(('ขุม', 'พลัง'), 44)\n",
      "(('ROG', 'Phone'), 44)\n",
      "(('ใน', 'ปี'), 43)\n",
      "(('ด้วย', 'การ'), 43)\n",
      "(('ไม่', 'ว่า'), 39)\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus import thai_words\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "f = open('data/content.txt','r',encoding='utf-8')\n",
    "content = f.read()\n",
    "f.close()\n",
    "\n",
    "tokens = [token for token in word_tokenize(content,engine='newmm')\n",
    "                             if len(token) > 1]\n",
    "\n",
    "bigrams = ngrams(tokens,2)\n",
    "bigrams_freq = Counter(bigrams)\n",
    "for common_gram in bigrams_freq.most_common(20):\n",
    "  print(common_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenize 2-gram by LLR (log-likelihood ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word pair: สมาร์ตโฟน, LLR score: 1159.93\n",
      "Word pair: ความละเอียด, LLR score: 956.91\n",
      "Word pair: เอไอ, LLR score: 769.40\n",
      "Word pair: เอซุส, LLR score: 709.63\n",
      "Word pair: พีซีบี, LLR score: 661.65\n",
      "Word pair: ขุมพลัง, LLR score: 631.81\n",
      "Word pair: ทีมข่าวสด, LLR score: 591.21\n",
      "Word pair: ข่าวสดไอที, LLR score: 585.42\n",
      "Word pair: ROG Phone, LLR score: 566.31\n",
      "Word pair: เล่นเกม, LLR score: 511.57\n",
      "Word pair: มาพร้อม, LLR score: 498.89\n",
      "Word pair: วางจำหน่าย, LLR score: 481.55\n",
      "Word pair: อัลตร้า, LLR score: 465.64\n",
      "Word pair: พียู, LLR score: 410.51\n",
      "Word pair: หน่วยประมวลผล, LLR score: 410.32\n",
      "Word pair: จากค่าย, LLR score: 396.50\n",
      "Word pair: ระบายความร้อน, LLR score: 391.48\n",
      "Word pair: iPad Air, LLR score: 363.10\n",
      "Word pair: AMD Ryzen, LLR score: 362.79\n",
      "Word pair: ตัวเครื่อง, LLR score: 358.07\n",
      "['สมาร์ตโฟน', 'ความละเอียด', 'เอไอ', 'เอซุส', 'พีซีบี', 'ขุมพลัง', 'ทีมข่าวสด', 'ข่าวสดไอที', 'ROG Phone', 'เล่นเกม', 'มาพร้อม', 'วางจำหน่าย', 'อัลตร้า', 'พียู', 'หน่วยประมวลผล', 'จากค่าย', 'ระบายความร้อน', 'iPad Air', 'AMD Ryzen', 'ตัวเครื่อง']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus import thai_words\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.util import dict_trie\n",
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def calculate_llr(k11, k12, k21, k22):\n",
    "  \"\"\"\n",
    "  Calculate Log-Likelihood Ratio\n",
    "  k11: frequency of word pair\n",
    "  k12: frequency of word1 without word2\n",
    "  k21: frequency of word2 without word1\n",
    "  k22: frequency of neither word\n",
    "  \"\"\"\n",
    "  n = k11 + k12 + k21 + k22\n",
    "  row1 = k11 + k12\n",
    "  row2 = k21 + k22\n",
    "  col1 = k11 + k21\n",
    "  col2 = k12 + k22\n",
    "\n",
    "  # Avoid division by zero\n",
    "  def ll(k, n, x):\n",
    "    if k == 0:\n",
    "      return 0\n",
    "    return k * math.log(k / (n * x))\n",
    "\n",
    "  # Calculate LLR\n",
    "  llr = 2 * (ll(k11, n, (row1 * col1) / (n * n)) +\n",
    "             ll(k12, n, (row1 * col2) / (n * n)) +\n",
    "             ll(k21, n, (row2 * col1) / (n * n)) +\n",
    "             ll(k22, n, (row2 * col2) / (n * n)))\n",
    "\n",
    "  return llr\n",
    "\n",
    "def is_english(text):\n",
    "  return bool(re.search(r'[a-zA-Z]', text))\n",
    "\n",
    "f = open('data/content.txt','r',encoding='utf-8')\n",
    "content = f.read()\n",
    "f.close()\n",
    "\n",
    "\n",
    "# Tokenize text\n",
    "tokens = [token for token in word_tokenize(content,engine='newmm')\n",
    "                          if len(token)>1]\n",
    "\n",
    "# Create word pairs (bigrams)\n",
    "word_pairs = [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "\n",
    "# Count frequencies\n",
    "pair_counts = Counter(word_pairs)\n",
    "word_counts = Counter(tokens)\n",
    "total_words = len(tokens)\n",
    "\n",
    "# Calculate LLR for each pair\n",
    "llr_scores = {}\n",
    "for pair, pair_freq in pair_counts.items():\n",
    "  word1, word2 = pair\n",
    "  k11 = pair_freq\n",
    "  k12 = word_counts[word1] - pair_freq\n",
    "  k21 = word_counts[word2] - pair_freq\n",
    "  k22 = total_words - k11 - k12 - k21\n",
    "\n",
    "  llr_scores[pair] = calculate_llr(k11, k12, k21, k22)\n",
    "\n",
    "# Print top collocations\n",
    "custom_dict_words = list()\n",
    "for pair, score in sorted(llr_scores.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "  if is_english(pair[0]) and is_english(pair[1]):\n",
    "    print(f\"Word pair: {' '.join(pair)}, LLR score: {score:.2f}\")\n",
    "    custom_dict_words.append(' '.join(pair))\n",
    "  else:\n",
    "    print(f\"Word pair: {''.join(pair)}, LLR score: {score:.2f}\")\n",
    "    custom_dict_words.append(''.join(pair))\n",
    "print(custom_dict_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### custom dict (thai_words + custom_dict_words by LLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สมาร์ตโฟน occurs 92 times\n",
      "ความละเอียด occurs 86 times\n",
      "เอไอ occurs 68 times\n",
      "เอซุส occurs 57 times\n",
      "พีซีบี occurs 47 times\n",
      "ขุมพลัง occurs 44 times\n",
      "ทีมข่าวสด occurs 0 times\n",
      "ข่าวสดไอที occurs 39 times\n",
      "ROG Phone occurs 44 times\n",
      "เล่นเกม occurs 59 times\n",
      "มาพร้อม occurs 90 times\n",
      "วางจำหน่าย occurs 36 times\n",
      "อัลตร้า occurs 27 times\n",
      "พียู occurs 27 times\n",
      "หน่วยประมวลผล occurs 32 times\n",
      "จากค่าย occurs 52 times\n",
      "ระบายความร้อน occurs 32 times\n",
      "iPad Air occurs 25 times\n",
      "AMD Ryzen occurs 27 times\n",
      "ตัวเครื่อง occurs 48 times\n"
     ]
    }
   ],
   "source": [
    "f = open('data/content.txt','r',encoding='utf-8')\n",
    "content = f.read()\n",
    "f.close()\n",
    "\n",
    "custom_words = set(thai_words())\n",
    "# print(len(custom_words))\n",
    "custom_words = custom_words.union(set(custom_dict_words))\n",
    "# print(len(custom_words))\n",
    "\n",
    "tokenizer = Tokenizer(custom_dict=custom_words,engine='newmm')\n",
    "tokens = [token for token in tokenizer.word_tokenize(content) if len(token) > 1]\n",
    "for word in custom_dict_words:\n",
    "  print(f'{word} occurs {tokens.count(word)} times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save custom dict(custom_words) to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "custom_dict_words.remove('ทีมข่าวสด')\n",
    "custom_dict_words.remove('ข่าวสดไอที')\n",
    "custom_dict_words.append('ทีมข่าวสดไอที')\n",
    "\n",
    "df_custom_words = pd.DataFrame({'custom':custom_dict_words})\n",
    "df_custom_words.to_json('data/custom_words.json',orient='table')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สมาร์ตโฟน occurs 92 times\n",
      "ความละเอียด occurs 86 times\n",
      "เอไอ occurs 68 times\n",
      "เอซุส occurs 57 times\n",
      "พีซีบี occurs 47 times\n",
      "ขุมพลัง occurs 44 times\n",
      "ROG Phone occurs 44 times\n",
      "เล่นเกม occurs 59 times\n",
      "มาพร้อม occurs 90 times\n",
      "วางจำหน่าย occurs 36 times\n",
      "อัลตร้า occurs 27 times\n",
      "พียู occurs 27 times\n",
      "หน่วยประมวลผล occurs 32 times\n",
      "จากค่าย occurs 52 times\n",
      "ระบายความร้อน occurs 32 times\n",
      "iPad Air occurs 25 times\n",
      "AMD Ryzen occurs 27 times\n",
      "ตัวเครื่อง occurs 48 times\n",
      "ทีมข่าวสดไอที occurs 39 times\n"
     ]
    }
   ],
   "source": [
    "f = open('data/content.txt','r',encoding='utf-8')\n",
    "content = f.read()\n",
    "f.close()\n",
    "\n",
    "custom_words = set(thai_words())\n",
    "# print(len(custom_words))\n",
    "custom_words = custom_words.union(set(custom_dict_words))\n",
    "# print(len(custom_words))\n",
    "\n",
    "tokenizer = Tokenizer(custom_dict=custom_words,engine='newmm')\n",
    "tokens = [token for token in tokenizer.word_tokenize(content) if len(token) > 1]\n",
    "for word in custom_dict_words:\n",
    "  print(f'{word} occurs {tokens.count(word)} times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54263\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization - BoW | CountVect | TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original documents:\n",
      "Document 1: the cat is on the mat\n",
      "Document 2: the dog is in the yard\n",
      "Document 3: the cat and the dog are playing\n",
      "\n",
      "## Bag of Words (Binary)\n",
      "BoW DataFrame:\n",
      "       and  are  cat  dog  in  is  mat  on  playing  the  yard\n",
      "Doc 1    0    0    1    0   0   1    1   1        0    1     0\n",
      "Doc 2    0    0    0    1   1   1    0   0        0    1     1\n",
      "Doc 3    1    1    1    1   0   0    0   0        1    1     0\n",
      "\n",
      "## Count Vectorizer\n",
      "Count Vectorizer DataFrame:\n",
      "       and  are  cat  dog  in  is  mat  on  playing  the  yard\n",
      "Doc 1    0    0    1    0   0   1    1   1        0    2     0\n",
      "Doc 2    0    0    0    1   1   1    0   0        0    2     1\n",
      "Doc 3    1    1    1    1   0   0    0   0        1    2     0\n",
      "\n",
      "## TF-IDF\n",
      "TF-IDF DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>playing</th>\n",
       "      <th>the</th>\n",
       "      <th>yard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553642</td>\n",
       "      <td>0.468699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.501310</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            and       are       cat       dog        in        is       mat  \\\n",
       "Doc 1  0.000000  0.000000  0.356457  0.000000  0.000000  0.356457  0.468699   \n",
       "Doc 2  0.000000  0.000000  0.000000  0.356457  0.468699  0.356457  0.000000   \n",
       "Doc 3  0.424396  0.424396  0.322764  0.322764  0.000000  0.000000  0.000000   \n",
       "\n",
       "             on   playing       the      yard  \n",
       "Doc 1  0.468699  0.000000  0.553642  0.000000  \n",
       "Doc 2  0.000000  0.000000  0.553642  0.468699  \n",
       "Doc 3  0.000000  0.424396  0.501310  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"the cat is on the mat\",\n",
    "    \"the dog is in the yard\",\n",
    "    \"the cat and the dog are playing\"\n",
    "]\n",
    "\n",
    "print(\"Original documents:\")\n",
    "for i, doc in enumerate(documents):\n",
    "  print(f\"Document {i+1}: {doc}\")\n",
    "\n",
    "print(\"\\n## Bag of Words (Binary)\")\n",
    "vocabulary = sorted(set(\" \".join(documents).split()))\n",
    "bow_vectors = []\n",
    "for doc in documents:\n",
    "  vector = {word: 1 if word in doc.split() else 0 for word in vocabulary}\n",
    "  bow_vectors.append(vector)\n",
    "\n",
    "bow_df = pd.DataFrame(bow_vectors, index=[f\"Doc {i+1}\" for i in range(len(documents))])\n",
    "print(\"BoW DataFrame:\")\n",
    "print(bow_df)\n",
    "\n",
    "print(\"\\n## Count Vectorizer\")\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(documents)\n",
    "count_df = pd.DataFrame(\n",
    "  count_matrix.toarray(),\n",
    "  columns=count_vectorizer.get_feature_names_out(),\n",
    "  index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
    ")\n",
    "print(\"Count Vectorizer DataFrame:\")\n",
    "print(count_df)\n",
    "\n",
    "print(\"\\n## TF-IDF\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_df = pd.DataFrame(\n",
    "  tfidf_matrix.toarray(),\n",
    "  columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "  index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
    ")\n",
    "print(\"TF-IDF DataFrame:\")\n",
    "display(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling - CountVect | TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khala\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 549)\n",
      "(102, 549)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_blognone = pd.read_json('data/blognone.json',orient='table')\n",
    "df_khaosod = pd.read_json('data/khaosod.json',orient='table')\n",
    "df = pd.concat([df_blognone,df_khaosod])\n",
    "\n",
    "df_custom_words = pd.read_json('data/custom_words.json',orient='table')\n",
    "custom_dict_words = df_custom_words['custom'].to_list()\n",
    "\n",
    "custom_words = set(thai_words())\n",
    "custom_words = custom_words.union(set(custom_dict_words))\n",
    "\n",
    "tokenizer = Tokenizer(custom_dict=custom_words,engine='newmm')\n",
    "\n",
    "def my_tokenizer(text):\n",
    "  tokens = [token for token in tokenizer.word_tokenize(text)\n",
    "                            if len(token) > 1]\n",
    "  return tokens\n",
    "\n",
    "cv = CountVectorizer(tokenizer=my_tokenizer,max_df=0.95,min_df=0.1)\n",
    "tfidf = TfidfVectorizer(tokenizer=my_tokenizer,max_df=0.95,min_df=0.1)\n",
    "\n",
    "count_matrix = cv.fit_transform(df['content'].tolist())\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'].tolist())\n",
    "\n",
    "print(count_matrix.shape)\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate sparsity | density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT\n",
      "sparsity = 0.76765241615772\n",
      "density = 0.23234758384228005\n",
      "\n",
      "TF-IDF\n",
      "sparsity = 0.76765241615772\n",
      "density = 0.23234758384228005\n"
     ]
    }
   ],
   "source": [
    "def calculate_sparsity(mx):\n",
    "  total_elements = mx.shape[0] * mx.shape[1]\n",
    "  non_zero_elements = mx.nnz\n",
    "  zero_elements = total_elements - non_zero_elements\n",
    "  sparsity = zero_elements / total_elements\n",
    "  return sparsity\n",
    "\n",
    "print('COUNT')\n",
    "print(f'sparsity = {calculate_sparsity(count_matrix)}')\n",
    "print(f'density = {1-calculate_sparsity(count_matrix)}')\n",
    "print()\n",
    "print('TF-IDF')\n",
    "print(f'sparsity = {calculate_sparsity(tfidf_matrix)}')\n",
    "print(f'density = {1-calculate_sparsity(tfidf_matrix)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ใน</th>\n",
       "      <th>ช่วง</th>\n",
       "      <th>ปี</th>\n",
       "      <th>ที่ผ่านมา</th>\n",
       "      <th>วงการ</th>\n",
       "      <th>เกม</th>\n",
       "      <th>มี</th>\n",
       "      <th>มากขึ้น</th>\n",
       "      <th>จาก</th>\n",
       "      <th>กลับมา</th>\n",
       "      <th>...</th>\n",
       "      <th>ภัย</th>\n",
       "      <th>เรียบ</th>\n",
       "      <th>มินิ</th>\n",
       "      <th>ตอบสนอง</th>\n",
       "      <th>สร้างสรรค์</th>\n",
       "      <th>มิติ</th>\n",
       "      <th>สวย</th>\n",
       "      <th>แอพพลิเคชั่น</th>\n",
       "      <th>(mp)</th>\n",
       "      <th>การถ่ายภาพ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089697</td>\n",
       "      <td>0.03627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051064</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037263</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030252</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039237</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063609</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.027307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.024921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.024921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127725</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072044</td>\n",
       "      <td>0.158693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ใน      ช่วง        ปี  ที่ผ่านมา  วงการ  เกม        มี  มากขึ้น  \\\n",
       "0    0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "1    0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "2    0.0  0.000000  0.000000        0.0    0.0  0.0  0.065779      0.0   \n",
       "3    0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "4    0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "..   ...       ...       ...        ...    ...  ...       ...      ...   \n",
       "97   0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "98   0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "99   0.0  0.024412  0.027307        0.0    0.0  0.0  0.000000      0.0   \n",
       "100  0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "101  0.0  0.000000  0.000000        0.0    0.0  0.0  0.000000      0.0   \n",
       "\n",
       "          จาก    กลับมา  ...  ภัย     เรียบ     มินิ  ตอบสนอง  สร้างสรรค์  \\\n",
       "0    0.000000  0.000000  ...  0.0  0.089697  0.03627      0.0    0.125517   \n",
       "1    0.000000  0.000000  ...  0.0  0.051064  0.00000      0.0    0.095275   \n",
       "2    0.000000  0.000000  ...  0.0  0.037263  0.00000      0.0    0.069526   \n",
       "3    0.000000  0.000000  ...  0.0  0.030252  0.00000      0.0    0.000000   \n",
       "4    0.000000  0.000000  ...  0.0  0.061646  0.00000      0.0    0.230037   \n",
       "..        ...       ...  ...  ...       ...      ...      ...         ...   \n",
       "97   0.000000  0.000000  ...  0.0  0.039237  0.00000      0.0    0.073209   \n",
       "98   0.000000  0.000000  ...  0.0  0.049731  0.00000      0.0    0.061859   \n",
       "99   0.022627  0.024921  ...  0.0  0.033766  0.00000      0.0    0.105000   \n",
       "100  0.072044  0.158693  ...  0.0  0.000000  0.00000      0.0    0.033432   \n",
       "101  0.000000  0.000000  ...  0.0  0.043862  0.00000      0.0    0.040919   \n",
       "\n",
       "         มิติ  สวย  แอพพลิเคชั่น      (mp)  การถ่ายภาพ  \n",
       "0    0.000000  0.0           0.0  0.024235    0.000000  \n",
       "1    0.000000  0.0           0.0  0.000000    0.000000  \n",
       "2    0.000000  0.0           0.0  0.000000    0.000000  \n",
       "3    0.000000  0.0           0.0  0.000000    0.000000  \n",
       "4    0.000000  0.0           0.0  0.000000    0.000000  \n",
       "..        ...  ...           ...       ...         ...  \n",
       "97   0.000000  0.0           0.0  0.063609    0.000000  \n",
       "98   0.000000  0.0           0.0  0.000000    0.000000  \n",
       "99   0.024921  0.0           0.0  0.127725    0.000000  \n",
       "100  0.000000  0.0           0.0  0.000000    0.044606  \n",
       "101  0.000000  0.0           0.0  0.000000    0.000000  \n",
       "\n",
       "[102 rows x 549 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf.vocabulary_)\n",
    "df_tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
